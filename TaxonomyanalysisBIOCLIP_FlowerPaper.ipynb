{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achaiallah-hub/Flower-Power-Paper-AGEE/blob/main/TaxonomyanalysisBIOCLIP_FlowerPaper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb6CMW6gRA6e",
        "outputId": "abae5849-3194-4a89-9b96-407a08de50d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio_client\n",
            "  Downloading gradio_client-1.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio_client) (2024.6.1)\n",
            "Collecting httpx>=0.24.1 (from gradio_client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio_client) (24.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (4.12.2)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio_client)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio_client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio_client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (3.15.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (4.66.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio_client) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (2.0.7)\n",
            "Downloading gradio_client-1.1.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, h11, httpcore, httpx, gradio_client\n",
            "Successfully installed gradio_client-1.1.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Images FAMILY"
      ],
      "metadata": {
        "id": "du80V9JZdxE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ9Qen1XQ8QH",
        "outputId": "5c38ab0c-5e42-4c3c-a2bc-9354f724e8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://imageomics-bioclip-demo.hf.space ✔\n",
            "{'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae', 'confidences': [{'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae', 'confidence': 0.9977979063987732}, {'label': 'Animalia Chordata Aves Ciconiiformes Ciconiidae', 'confidence': 0.0007570742163807154}, {'label': 'Animalia Chordata Aves Eurypygiformes Eurypygidae', 'confidence': 0.0003283641126472503}, {'label': 'Animalia Chordata Reptilia Testudines Emydidae', 'confidence': 0.0002732095308601856}, {'label': 'Animalia Chordata Aves Suliformes Anhingidae', 'confidence': 9.805886656977236e-05}]}\n"
          ]
        }
      ],
      "source": [
        "from gradio_client import Client, handle_file\n",
        "\n",
        "client = Client(\"imageomics/bioclip-demo\")\n",
        "result = client.predict(\n",
        "\t\timg=handle_file('https://live.staticflickr.com/7292/12876707363_124629b06b_c.jpg'),\n",
        "\t\trank=\"Family\",\n",
        "\t\tapi_name=\"/open_domain_classification\"\n",
        ")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Images Family"
      ],
      "metadata": {
        "id": "hcNva-j_dz-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import requests\n",
        "import PIL\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Initialize the Gradio client\n",
        "client = Client(\"imageomics/bioclip-demo\")\n",
        "\n",
        "# Function to get the classification result for an image URL\n",
        "def get_classification_result(url):\n",
        "    if not url:\n",
        "        return None  # Skip empty URLs\n",
        "    try:\n",
        "        result = client.predict(\n",
        "            img=handle_file(url),\n",
        "            rank=\"Family\",\n",
        "            api_name=\"/open_domain_classification\"\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL {url}: {e}\")\n",
        "        return None  # Skip URLs that cause errors\n",
        "\n",
        "# Function to parse the result and extract relevant information\n",
        "def parse_result(result):\n",
        "    if result is None:\n",
        "        return \"\", 0  # Return default values for errors\n",
        "    label = result.get('label', '')\n",
        "    highest_confidence = max(result.get('confidences', []), key=lambda x: x['confidence'], default={}).get('confidence', 0)\n",
        "    return label, highest_confidence\n",
        "\n",
        "\n",
        "#add dataframe from google drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your DataFrame file in Google Drive\n",
        "file_path = '/content/drive/My Drive/dataflickr.csv' #CHANGE TO YOU DF\n",
        "\n",
        "# Read the DataFrame from the file\n",
        "df = pd.read_csv(file_path)\n",
        "df\n",
        "\n",
        "# Apply the classification function and parse results to new columns\n",
        "df[['label', 'confidence']] = df['image_url'].apply(lambda url: pd.Series(parse_result(get_classification_result(url))))\n",
        "\n",
        "df\n",
        "\n",
        "\n",
        "# save the updated DataFrame back to Google Drive\n",
        "output_file_path = '/content/drive/My Drive/dataflickr_family.csv'\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdQn8HZscuQ0",
        "outputId": "3648d5c3-da76-4856-b791-667512c27bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://imageomics-bioclip-demo.hf.space ✔\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Images *GENUS*"
      ],
      "metadata": {
        "id": "ugVOXNc2A1u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio_client import Client, handle_file\n",
        "\n",
        "client = Client(\"imageomics/bioclip-demo\")\n",
        "result = client.predict(\n",
        "\t\timg=handle_file('https://live.staticflickr.com/7292/12876707363_124629b06b_c.jpg'),\n",
        "\t\trank=\"Genus\",\n",
        "\t\tapi_name=\"/open_domain_classification\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4QsiHqtBDXE",
        "outputId": "3ef74fb4-b690-48db-e99f-374478f48895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://imageomics-bioclip-demo.hf.space ✔\n",
            "{'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae Ardea', 'confidences': [{'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae Ardea', 'confidence': 0.9795452952384949}, {'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae Tigrisoma', 'confidence': 0.01115737110376358}, {'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae Syrigma', 'confidence': 0.0020422579254955053}, {'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae Cochlearius', 'confidence': 0.0014523824211210012}, {'label': 'Animalia Chordata Aves Pelecaniformes Ardeidae Butorides', 'confidence': 0.0013868918176740408}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Images *GENUS*"
      ],
      "metadata": {
        "id": "2mSAA4ebqFKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gradio_client import Client\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from transformers import pipeline\n",
        "import uuid\n",
        "import urllib.request\n",
        "import PIL\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Initialize the Gradio client\n",
        "client = Client(\"imageomics/bioclip-demo\")\n",
        "\n",
        "# Function to get the classification result for an image URL\n",
        "def get_classification_result(url):\n",
        "    if not url:\n",
        "        return None  # Skip empty URLs\n",
        "    try:\n",
        "        result = client.predict(\n",
        "            img=handle_file(url),\n",
        "            rank=\"Genus\",\n",
        "            api_name=\"/open_domain_classification\"\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL {url}: {e}\")\n",
        "        return None  # Skip URLs that cause errors\n",
        "\n",
        "# Function to parse the result and extract relevant information\n",
        "def parse_result(result):\n",
        "    if result is None:\n",
        "        return \"\", 0  # Return default values for errors\n",
        "    label = result.get('label', '')\n",
        "    highest_confidence = max(result.get('confidences', []), key=lambda x: x['confidence'], default={}).get('confidence', 0)\n",
        "    return label, highest_confidence\n",
        "\n",
        "\n",
        "#add dataframe from google drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your DataFrame file in Google Drive\n",
        "file_path = '/content/drive/My Drive/inaturalistdata.csv' #CHANGE TO YOU DF\n",
        "\n",
        "# Read the DataFrame from the file\n",
        "df = pd.read_csv(file_path)\n",
        "df\n",
        "\n",
        "# Apply the classification function and parse results to new columns\n",
        "df[['label', 'confidence']] = df['image_url'].apply(lambda url: pd.Series(parse_result(get_classification_result(url))))\n",
        "\n",
        "df\n",
        "\n",
        "\n",
        "# save the updated DataFrame back to Google Drive\n",
        "output_file_path = '/content/drive/My Drive/inaturalistdata_genus.csv'\n",
        "df.to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mGNrTO8qYTv",
        "outputId": "ebe1ffbe-97ad-4293-94ac-d2b26c4a654b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://imageomics-bioclip-demo.hf.space ✔\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}